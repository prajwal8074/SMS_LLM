AWSTemplateFormatVersion: '2010-09-09'
Description: AWS CloudFormation template for a Voice Gateway using Lambda, S3, Transcribe, Translate, Polly, and API Gateway (Single Language Focus).

Parameters:
  # S3 Bucket Name Prefix: A unique prefix for your S3 bucket name.
  # The actual bucket name will be generated with a unique suffix.
  BucketNamePrefix:
    Type: String
    Description: A unique prefix for the S3 bucket name where audio and transcripts will be stored.
    MinLength: 3
    MaxLength: 50
    AllowedPattern: "[a-z0-9](-*[a-z0-9])*"
    ConstraintDescription: Must be lowercase alphanumeric characters and hyphens, and start/end with alphanumeric.

  # Gemini API Key for LLM Integration
  GeminiApiKey:
    Type: String
    Description: The API Key for the Google Gemini LLM service.
    NoEcho: true # Hides the value in CloudFormation console after deployment

  # Facebook Verify Token for Webhook GET requests (if integrating with Facebook Messenger)
  FacebookVerifyToken:
    Type: String
    Description: The verification token for Facebook Messenger webhook (if used). Set a strong random string.
    NoEcho: true # Hides the value in CloudFormation console after deployment

  LambdaMemory:
    Type: Number
    Default: 512
    Description: Memory allocated to the Lambda function in MB.
    MinValue: 128
    MaxValue: 1024

  LambdaTimeout:
    Type: Number
    Default: 90
    Description: Maximum execution time for the Lambda function in seconds.
    MinValue: 10
    MaxValue: 300

Resources:
  # S3 Bucket for Audio and Transcripts
  VoiceGatewayBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub "${BucketNamePrefix}-${AWS::AccountId}-${AWS::Region}"
      # Set Object Ownership to ensure objects written by other services (like Transcribe) are readable by the bucket owner.
      ObjectOwnership: BucketOwnerPreferred
      Tags:
        - Key: Project
          Value: VoiceGateway
    DeletionPolicy: Retain # IMPORTANT: Retains the bucket upon stack deletion to prevent data loss.

  # IAM Role for Lambda Function
  VoiceGatewayLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        # Policy for CloudWatch Logs
        - PolicyName: VoiceGatewayCloudWatchLogsPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/${VoiceGatewayLambdaFunction}:*"
        # Policy for S3, Transcribe, Translate, and Polly access
        - PolicyName: VoiceGatewayServiceAccessPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              # S3 permissions for Lambda and Transcribe output
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:ListBucket
                  - s3:DeleteObject # For cleanup of input/transcript files
                Resource:
                  - !GetAtt VoiceGatewayBucket.Arn # Specific bucket ARN
                  - !Sub "${VoiceGatewayBucket.Arn}/*" # All objects within the bucket
              # Amazon Transcribe permissions
              - Effect: Allow
                Action:
                  - transcribe:*
                Resource: "*"
              # Amazon Translate permissions
              - Effect: Allow
                Action:
                  - translate:*
                Resource: "*"
              # Amazon Polly permissions
              - Effect: Allow
                Action:
                  - polly:*
                Resource: "*"

  # Lambda Function
  VoiceGatewayLambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub "VoiceGatewayProcessor-${AWS::Region}"
      Handler: index.lambda_handler
      Runtime: python3.9 # Or python3.10, python3.11 based on availability and preference
      MemorySize: !Ref LambdaMemory
      Timeout: !Ref LambdaTimeout
      Role: !GetAtt VoiceGatewayLambdaRole.Arn
      Environment:
        Variables:
          S3_BUCKET_NAME: !Ref VoiceGatewayBucket
          GEMINI_API_KEY: !Ref GeminiApiKey
          FB_VERIFY_TOKEN: !Ref FacebookVerifyToken # Added FB_VERIFY_TOKEN
      Code:
        ZipFile: |
          import json
          import base64
          import os
          import boto3
          import uuid
          from botocore.exceptions import ClientError
          import time
          from urllib.request import Request, urlopen

          # Initialize AWS clients
          s3_client = boto3.client('s3')
          transcribe_client = boto3.client('transcribe')
          translate_client = boto3.client('translate')
          polly_client = boto3.client('polly')

          # Configuration (replace with your actual S3 bucket and LLM API details)
          S3_BUCKET_NAME = os.environ.get('S3_BUCKET_NAME', 'your-voice-gateway-audio-bucket-12345')
          TARGET_LLM_LANGUAGE = 'en'
          DEFAULT_FARMER_LANGUAGE = 'hi-IN' # Updated to hi-IN
          # Retrieve the Facebook Verify Token from environment variables
          FB_VERIFY_TOKEN = os.environ.get('FB_VERIFY_TOKEN')


          def lambda_handler(event, context):
              print("--- Full Lambda Event Received ---")
              print(json.dumps(event, indent=2))

              http_method = event.get('httpMethod')

              # --- Facebook Webhook Verification Logic ---
              if http_method == 'GET':
                  print("Received GET request for Webhook verification.")
                  query_params = event.get('queryStringParameters', {})
                  mode = query_params.get('hub.mode')
                  token = query_params.get('hub.verify_token')
                  challenge = query_params.get('hub.challenge')

                  if mode == 'subscribe' and token == FB_VERIFY_TOKEN:
                      print(f"Webhook verification successful. Returning challenge: {challenge}")
                      return {
                          'statusCode': 200,
                          'headers': {
                              'Content-Type': 'text/plain' # Facebook expects plain text for challenge
                          },
                          'body': challenge
                      }
                  else:
                      print("Webhook verification failed: Invalid mode or token.")
                      return {
                          'statusCode': 403, # Forbidden
                          'body': 'Verification failed'
                      }

              # --- Original Voice Processing Logic (for POST requests) ---
              elif http_method == 'POST':
                  print("Received POST request for voice processing.")
                  body_data = {} # Initialize to empty dict

                  try:
                      # We already know isBase64Encoded is true from previous logs
                      # So, we'll force the Base64 decode path and print steps
                      raw_body_from_event = event.get('body', None)
                      if raw_body_from_event: # Only proceed if body is not empty/None
                          print("Attempting Base64 decode of raw body...")
                          decoded_bytes = base64.b64decode(raw_body_from_event)
                          decoded_string = decoded_bytes.decode('utf-8')
                          print(f"Successfully Base64 decoded. Decoded string length: {len(decoded_string)}")
                          print(f"Decoded string (first 200 chars): {decoded_string[:200]}")
                          print(f"Decoded string (last 200 chars): {decoded_string[-200:]}")

                          print("Attempting JSON parse of decoded string...")
                          body_data = json.loads(decoded_string)
                          print("Successfully parsed JSON into dictionary.")
                      else:
                          raise ValueError("Received empty or None body from API Gateway.")

                  except json.JSONDecodeError as e:
                      print(f"CRITICAL ERROR: JSON Decode Failed - {e}")
                      print(f"String that failed JSON parse (first 200 chars): {decoded_string[:200] if 'decoded_string' in locals() else 'N/A'}")
                      print(f"String that failed JSON parse (last 200 chars): {decoded_string[-200:] if 'decoded_string' in locals() else 'N/A'}")
                      return {
                          'statusCode': 500,
                          'body': json.dumps({'message': f'Failed to parse JSON body after decode: {str(e)}'})
                      }
                  except UnicodeDecodeError as e:
                      print(f"CRITICAL ERROR: Unicode Decode Failed - {e}")
                      return {
                          'statusCode': 500,
                          'body': json.dumps({'message': f'Failed to decode Base64 to UTF-8: {str(e)}'})
                      }
                  except Exception as e:
                      print(f"CRITICAL ERROR: Unexpected exception during body processing - {e}")
                      return {
                          'statusCode': 500,
                          'body': json.dumps({'message': f'An unexpected error occurred during body parsing: {str(e)}'})
                      }

                  # --- Now, proceed with extracting data from the 'body_data' dictionary ---
                  audio_base64 = body_data.get('audio_data')
                  farmer_language_code = body_data.get('farmer_language_code', DEFAULT_FARMER_LANGUAGE)

                  if not audio_base64:
                      print("Validation Error: Missing audio_data in request body.")
                      return {
                          'statusCode': 400,
                          'body': json.dumps({'message': 'Missing audio_data in request body'})
                      }

                  # --- 2. Upload Audio to S3 ---
                  try:
                      audio_binary_data = base64.b64decode(audio_base64)
                      audio_filename = f"incoming_audio/{uuid.uuid4()}.mp3" # Ensure .mp3 extension
                      s3_client.put_object(Bucket=S3_BUCKET_NAME, Key=audio_filename, Body=audio_binary_data)
                      audio_s3_uri = f"s3://{S3_BUCKET_NAME}/{audio_filename}"
                      print(f"Audio uploaded to S3: {audio_s3_uri}")
                  except ClientError as e:
                      print(f"S3 Upload Error: {e}")
                      return {
                          'statusCode': 500,
                          'body': json.dumps({'message': f'Failed to upload audio to S3: {str(e)}'})
                      }

                  # --- 3. Transcribe Audio (using Amazon Transcribe) ---
                  transcription_job_name = f"voice-transcript-{uuid.uuid4()}"
                  try:
                      transcribe_client.start_transcription_job(
                          TranscriptionJobName=transcription_job_name,
                          LanguageCode=farmer_language_code, # Use the dynamic language code
                          MediaFormat='mp3', # Ensure this matches your audio format
                          Media={'MediaFileUri': audio_s3_uri},
                          OutputBucketName=S3_BUCKET_NAME,
                          OutputKey=f'transcripts/{transcription_job_name}.json'
                      )
                      print(f"Transcribe job started: {transcription_job_name}")

                      # Poll for transcription job completion (simplified for demo, production might use SNS/SQS)
                      max_attempts = 120 # 120 * 5 seconds = 10 minutes
                      for i in range(max_attempts):
                          job_status = transcribe_client.get_transcription_job(TranscriptionJobName=transcription_job_name)
                          status = job_status['TranscriptionJob']['TranscriptionJobStatus']
                          if status == 'COMPLETED':
                              print("Transcription job completed successfully.")
                              transcript_uri = job_status['TranscriptionJob']['Transcript']['TranscriptFileUri']
                              # Fetch transcript content from S3 (Transcribe places it in the S3 bucket)
                              response = urlopen(transcript_uri)
                              transcript_content = json.loads(response.read().decode('utf-8'))
                              transcribed_text = transcript_content['results']['transcripts'][0]['transcript']
                              print(f"Transcribed Text: {transcribed_text}")
                              break
                          elif status == 'FAILED':
                              print(f"Transcription job failed: {job_status['TranscriptionJob'].get('FailureReason')}")
                              raise Exception(f"Transcription failed: {job_status['TranscriptionJob'].get('FailureReason')}")
                          print(f"Transcription job status: {status}. Waiting... ({i+1}/{max_attempts})")
                          time.sleep(5)
                      else: # This block executes if the loop completes without a 'break'
                          raise Exception("Transcription job timed out.")

                  except Exception as e:
                      print(f"Transcribe Error: {e}")
                      return {
                          'statusCode': 500,
                          'body': json.dumps({'message': f'An AWS service error occurred during transcription: {str(e)}'})
                      }


                  # --- 4. Send Transcribed Text to LLM (Gemini API) ---
                  llm_response_text = ""
                  try:
                      # Prepare prompt for LLM
                      prompt = f"The farmer said: '{transcribed_text}'. Provide a concise, helpful, and empathetic response as if you are a local agricultural expert. Your response should be brief, directly address the farmer's query or concern, and encourage further interaction. If the farmer is asking a question, provide a direct answer. Respond in the same language the farmer spoke, or {farmer_language_code} if the language is not explicitly detected but was provided."

                      # Check for API key presence
                      api_key = os.environ.get('GEMINI_API_KEY')
                      if not api_key:
                          raise ValueError("GEMINI_API_KEY environment variable not set.")

                      chat_history = []
                      chat_history.append({ "role": "user", "parts": [{ "text": prompt }] })

                      payload = { "contents": chat_history }

                      # NOTE: The base URL might be region-specific or differ slightly based on model
                      # This example uses a common v1beta endpoint.
                      gemini_api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}"

                      req = Request(
                          gemini_api_url,
                          data=json.dumps(payload).encode('utf-8'),
                          headers={'Content-Type': 'application/json'},
                          method='POST'
                      )

                      # Set a timeout for the LLM API call
                      with urlopen(req, timeout=30) as res: # 30 second timeout for LLM
                          llm_api_response = json.loads(res.read().decode('utf-8'))
                          if llm_api_response and llm_api_response.get('candidates'):
                              llm_response_text = llm_api_response['candidates'][0]['content']['parts'][0]['text']
                              print(f"LLM Response: {llm_response_text}")
                          else:
                              print(f"LLM API did not return expected content: {llm_api_response}")
                              llm_response_text = "I'm sorry, I couldn't generate a response at this time."

                      print(f"LLM Raw Response: {llm_response_text}")

                  except ValueError as e:
                      print(f"LLM API Configuration Error: {e}")
                      llm_response_text = f"An internal configuration error occurred with the AI assistant: {str(e)}"
                  except Exception as e:
                      print(f"LLM API Call Error: {e}")
                      llm_response_text = f"I'm sorry, I couldn't get a response from the AI assistant: {str(e)}"

                  final_response_text = llm_response_text # Use LLM's response as the final text


                  # --- 5. Translate LLM Response (if necessary) ---
                  # Assume LLM responds in the farmer's language, but if not, translate
                  # For simplicity, if LLM responded in English and farmer_language_code is hi-IN, translate
                  # This part assumes LLM tries to respond in the target language.
                  # If the LLM's default is English and farmer_language_code is not 'en-US', then translate.
                  # We'll stick to the current prompt that asks LLM to respond in farmer's language.
                  # So, translation step is primarily for farmer's query, but LLM also outputs in target language.

                  # If you want to force LLM to always respond in English and then translate, you'd change the LLM prompt
                  # and uncomment/implement a translation step here:
                  if farmer_language_code != 'en-US' and llm_response_text: # Simple example logic
                      try:
                          translate_response = translate_client.translate_text(
                              Text=llm_response_text,
                              SourceLanguageCode='en', # Assuming LLM outputs English
                              TargetLanguageCode=farmer_language_code.split('-')[0] # Use primary language code
                          )
                          final_response_text = translate_response['TranslatedText']
                          print(f"Translated LLM Response: {final_response_text}")
                      except ClientError as e:
                          print(f"Translate Error: {e}")
                          final_response_text = "I couldn't translate the message."
                  # --- 6. Synthesize Speech (using Amazon Polly) ---
                  audio_response_base64 = ""
                  try:
                      polly_response = polly_client.synthesize_speech(
                          Text=final_response_text,
                          OutputFormat='mp3',
                          VoiceId='Kajal', # Your selected voice, requires 'neural' engine
                          LanguageCode=farmer_language_code, # Use the dynamic language code
                          Engine='neural' # Explicitly specify the neural engine for Kajal
                      )
                      audio_stream = polly_response['AudioStream'].read()
                      audio_response_base64 = base64.b64encode(audio_stream).decode('utf-8')
                      print("Speech synthesized with Polly.")
                  except ClientError as e:
                      print(f"Polly Error: {e}")
                      return {
                          'statusCode': 500,
                          'body': json.dumps({'message': f'An AWS service error occurred during speech synthesis: {str(e)}'})
                      }
                  except Exception as e:
                      print(f"Polly General Error: {e}")
                      return {
                          'statusCode': 500,
                          'body': json.dumps({'message': f'An unexpected error occurred during speech synthesis: {str(e)}'})
                      }

                  # --- 7. Return Response ---
                  return {
                      'statusCode': 200,
                      'headers': {
                          'Content-Type': 'application/json'
                      },
                      'body': json.dumps({
                          'message': 'Processing complete',
                          'transcribed_text': transcribed_text,
                          'llm_response': llm_response_text,
                          'final_spoken_text': final_response_text,
                          'audio_response_base64': audio_response_base64
                      })
                  }
              else:
                  print(f"Unsupported HTTP method: {http_method}")
                  return {
                      'statusCode': 405, # Method Not Allowed
                      'body': json.dumps({'message': 'Method Not Allowed'})
                  }
